{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d88013",
   "metadata": {},
   "source": [
    "# Develop a Web chatbot using gradio and OpenAI's GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378fc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee97afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b1585",
   "metadata": {},
   "source": [
    "## Read pdf files and use them as context for a chatbot using gradio and OpenAI's GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2deb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"../resume/resume_khangbuitranduy_updated.pdf\")\n",
    "resume = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        resume += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7dbc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(+84)-815-594-665 |       khang.buitranduycse@hcmut.edu.vn |      khangbkk23 |       khangbkk23\n",
      "KHANG BUI TRAN DUY\n",
      "AI ENGINEER / DATA SCIENCE \n",
      "2023 - 2027\n",
      "May 2025 - PresentI’m a highly motivated third-year Computer Science student with a strong foundation in Machine Learning, Data\n",
      "Science, Computer Vision, and Natural Language Processing. I’m passionate about Artificial Intelligence,\n",
      "continuously expanding my knowledge and applying it to real-world problems. I have hands-on experience with\n",
      "TensorFlow, PyTorch, and Scikit-learn, along with solid skills in Machine Learning and Deep Learning, and growing\n",
      "expertise in Reinforcement Learning. Beyond academics, I actively engage in social and community activities, which have\n",
      "strengthened my teamwork, communication, and leadership skills. As an aspiring AI Engineer and Data Scientist, I am\n",
      "eager to collaborate with experts, tackle challenging projects, and further develop my expertise with the goal of building\n",
      "scalable, intelligent systems and advancing research on AI agents.\n",
      "I. ABOUT ME\n",
      "Designed and implemented an Online Continual Learning, Nested Learning framework in PyTorch for\n",
      "reinforcement learning agents, integrating DER++ replay buffer, loss-based task boundary detection, and\n",
      "regularization-based methods (Online EWC, Synaptic Intelligence).\n",
      "Developed a robust evaluation pipeline, including Final Average Accuracy (FAA), Forgetting Measure, and Loss\n",
      "Dynamics, to assess catastrophic forgetting and stability–plasticity trade-offs. \n",
      "Conducted experiments on CIFAR-10 and CIFAR-100 sequential benchmarks, systematically comparing replay- and\n",
      "regularization-based strategies for memory retention.\n",
      "Achieved higher task retention and reduced forgetting, providing insights into the role of memory buffer size and\n",
      "regularization strength in online continual learning.\n",
      "Collaborated with research team to analyze results and prepare for academic publication and conference presentations.University of Technology - VNU-HCM - Faculty of Computer Science and Engineering (Optimization AI Lab)\n",
      "Research Team  M em ber (Team  of 2) —  Topic: Optim ization of Continual Learning Strategy\n",
      "for Reinforcem ent Learning\n",
      "III. RESEARCH EXPERIENCE\n",
      "Programming Languages: Python, Java (Core), C++, JavaScript.\n",
      "ML/DL Frameworks:\n",
      "Frameworks: PyTorch, TensorFlow, Scikit-learn\n",
      "Learning paradigms: Supervised, Unsupervised\n",
      "Model development: training, validation, evaluation\n",
      "Optimization and tuning: learning rate scheduling, regularization\n",
      "Natural Language Processing:\n",
      "Text preprocessing: tokenization, normalization, stopword removal, stemming, lemmatization, etc.\n",
      "Feature extraction: Bag of Words, TF-IDF, N-gram models.\n",
      "Text representation: Word Embedding, Semantic Vector Embedding.\n",
      "NLP tasks: Text Classification, Sentiment Analysis, Named Entity Recognition (NER).\n",
      "Retrieval-Augmented Generation (RAG) systems combining vector search and generation.\n",
      "Computer Vision:\n",
      "Tasks: Image classification, Object detection\n",
      "Detection models: YOLO, Faster R-CNN\n",
      "CNN backbones: ResNet, MobileNet, EfficientNet\n",
      "Data augmentation, evaluation and visualization for vision models\n",
      "IV. TECHNICAL SKILLSUniversity of Technology - Vietnam National University, Ho Chi Minh City\n",
      "Bachelor of Engineering in Com puter Science, M inors in Applied Artificial Intelligence\n",
      "CPA: 3.6/4.0\n",
      "II. EDUCATION\n",
      "Sep 2023 - Apr 2027\n",
      "RepositoryJul 2025 - Present\n",
      "VI. LEADERSHIP & EXTRACURRICULAR ACTIVITIES SKILLS\n",
      "Project goal: Built an autonomous driving system that integrates reinforcement learning with real-time object detection\n",
      "for safer and adaptive navigation.\n",
      "Details:\n",
      "Applied Deep Deterministic Policy Gradient (DDPG) with actor–critic–agent modules to optimize continuous\n",
      "control of steering and acceleration.\n",
      "Developed and benchmarked object detection modules for self-driving perception using YOLOv11 and fine-tuned\n",
      "Faster R-CNN architectures with ResNet and MobileNet backbones.\n",
      "Implemented a robust training pipeline with advanced augmentation (rotation, noise, color jitter), AdamW\n",
      "optimizer, OneCycleLR scheduler, and early stopping, ensuring stable convergence.\n",
      "Findings: YOLOv11 outperformed fine-tuned models in terms of accuracy and inference speed, making it more\n",
      "effective for real-time scenarios. However, the fine-tuned Faster R-CNN models showed strong potential for\n",
      "future improvement, offering flexibility in backbone selection and research extensions.\n",
      "Designed a modular PyTorch framework supporting scalable training, reproducibility, and detailed loss dynamics\n",
      "analysis, enabling further research and deployment.1. Self-Driving Car Detect Objects Module (Reinforcement Learning, Deep Learning) Repository\n",
      "VII. PROJECTSM ember of the Executive Committee, Ho Chi M inh Communist Youth Union – Faculty of CSE.\n",
      "Contributed to faculty-level student initiatives and community development programs.\n",
      "Leader, Volunteer Campaign “Xuan Tinh nguyen” (2025) – Faculty of CSE\n",
      "Vice Leader, Volunteer Campaign “Mua he xanh” (2024) – Ho Chi Minh City Front, Faculty of CSE\n",
      "Vice Leader, CSE Summer School (2024) - Faculty of CSE\n",
      "Key skills developed:\n",
      "Teamwork: Collaborated effectively with peers and local communities to achieve shared goals.\n",
      "Team Management: Directed and motivated groups, delegated tasks, and ensured smooth execution of activities.\n",
      "Time Management: Balanced academic responsibilities with leadership roles, prioritizing tasks to meet deadlines.\n",
      "Problem-Solving: Tackled logistical and organizational challenges during campaigns, developing practical and\n",
      "adaptive solutions.\n",
      "High Intensity Working: Maintained high performance under pressure and tight schedules, ensuring\n",
      "successful completion of demanding projects.Strong analytical thinking with solid foundations in algorithms, data structures, and mathematical modeling for AI.\n",
      "Ability to design and implement end-to-end AI systems, from data preprocessing and model development to\n",
      "deployment.\n",
      "Experience translating research ideas into working implementations, attention to reproducibility and evaluation.\n",
      "System-level thinking in AI workflows, using UML and architectural diagrams to structure complex pipelines.\n",
      "Comfortable working in Linux-based environments, collaborating via Git, and adapting quickly to new tools and\n",
      "frameworks.\n",
      "Self-motivated learner with hands-on experience across NLP, Computer Vision, Reinforcement Learning, and Time-\n",
      "Series, able to ramp up fast in new domains.\n",
      "V. CORE COMPETENCIESReinforcement Learning\n",
      "Algorithms: DDPG, Actor–Critic\n",
      "Continuous control environments\n",
      "Continual learning techniques: Experience Replay, Elastic Weight Consolidation (EWC)\n",
      "Time-Series Analysis\n",
      "Spatio-temporal data modeling\n",
      "Feature engineering: Sliding Window, Time Encoding\n",
      "Dual Embedding (Entity/Spatial Embeddings) with BiLSTM architectures\n",
      "MLOps / Deployment: Model serving via FastAPI and Flask, Containerization and deployment using Docker, CI/CD\n",
      "workflows for machine learning systems\n",
      "Databases & Tools: MongoDB, SQL Server, Git, Conda, Poetry, Postman, Jupyter Notebook, Google Colab, VercelJul - Sep 2025\n",
      "Project goal: Developed deep learning models to classify sentences in scientific abstracts into structured roles (e.g.,\n",
      "objective, methods, results, conclusions), enabling researchers to efficiently skim papers and accelerate literature review.\n",
      "Details:\n",
      "Implemented a diverse range of models including baseline statistical approaches, token-level Conv1D networks,\n",
      "pretrained embeddings, character-level models, and hybrid architectures.\n",
      "Applied both token-level and character-level representations to capture semantic meaning and handle\n",
      "rare/unknown words effectively.\n",
      "Integrated positional features alongside token and character embeddings to model sequential structure of abstracts.\n",
      "Designed and trained a tri-brid embedding model (token + character + positional) that significantly outperformed\n",
      "all baselines, achieving about 81% accuracy.\n",
      "Developed an evaluation framework with precision/recall/F1 comparisons and error analysis, enabling deeper\n",
      "understanding of model behavior and misclassifications.\n",
      "Demonstrated that token-level CNNs provide strong performance but benefit further when enriched with character-\n",
      "level and positional signals. This experience showed that hybrid and tribrid approaches outperform single-\n",
      "representation models by combining complementary strengths.\n",
      "Highlighted the potential of deep multi-input architectures for improving scientific text understanding.Repository\n",
      "Nov - Dec 2025\n",
      "Project Goal: Developed a unified deep learning framework using Dual Embedding BiLSTM to forecast multi-station\n",
      "Air Quality Index (AQI) across Vietnam, addressing complex spatio-temporal dependencies.\n",
      "Details:\n",
      "Engineered a robust ETL pipeline using Pandas, implementing advanced time-series preprocessing techniques\n",
      "including Sliding Window, Cyclical Time Encoding (Sin/Cos), and Lag/Rolling features to transform raw\n",
      "environmental data into supervised learning tensors.\n",
      "Architected a novel Dual Embedding BiLSTM with Attention model: Leveraged Entity Embeddings to capture\n",
      "spatial heterogeneity (Station/Region ID) and Bidirectional LSTM layers to model long-term temporal dependencies\n",
      "efficiently.\n",
      "Implemented advanced training strategies including Gradient Clipping, Learning Rate Scheduling, and Early\n",
      "Stopping. Designed a custom Weighted MSE/Huber Loss function to improve model robustness against extreme\n",
      "outliers and data imbalance.\n",
      "Developed a Recursive Forecasting strategy to extend prediction horizons to 7 days, successfully integrating the\n",
      "model into a  web application using Flask and Leaflet.js for real-time geo-visualization and interactive analytics.\n",
      "Achieved a competitive RMSE of ~0.43 on the test set, demonstrating the efficacy of spatial embeddings in multi-\n",
      "station forecasting tasks compared to traditional isolated modeling approaches.4. Vietnam AQI Forecasting System: Spatio-Temporal Regression  (Deep Learning) Repository3. SkimLit: Sequential Sentence Classification in Scientific Abstracts\n",
      "(NLP, Deep Learning)Jul  - Aug 2025\n",
      "Project goal:  Conducted systematic experiments on a custom 10-class food dataset and the Food101 benchmark (101\n",
      "classes, 100K+ images) to evaluate CNN performance under varying choices, training setups, regularization strategies.\n",
      "Details:\n",
      "Implemented and compared multiple baseline CNNs (shallow Conv2D models, simplified CNN, refined CNN\n",
      "with dropout/batch norm) and optimized training using Adam optimizer with learning rate tuning.\n",
      "Apply data augmentation (rotation, shifting, zoom, flipping) to mitigate overfitting, improve validation accuracy.\n",
      "Integrated regularization techniques including dropout, early stopping, and architecture restructuring to balance\n",
      "model capacity and generalization.\n",
      "Scaled experiments from small CNNs to larger refined models (>2M parameters), observing trade-offs between\n",
      "model complexity, training loss convergence, and validation accuracy.\n",
      "Built an evaluation pipeline for loss/accuracy monitoring, comparative analysis across models, and visualization of\n",
      "overfitting dynamics.\n",
      "Achieved about 80% validation accuracy on large-scale Food101 dataset and high performance on custom 10-\n",
      "class dataset, demonstrating the effectiveness of refined CNNs with augmentation and regularization for large-label-\n",
      "space image classification.2. Food Image Classification with Large Label Space (CV, Deep Learning) RepositoryVietnamese: Native.\n",
      "English: \n",
      "TOEIC L&R: 855\n",
      "Excellence (Equivalent to CEFR C1 level)\n",
      "Professional working proficiency.\n",
      "Fluent in technical discussions.\n",
      "Strong presentation and documentation skills.\n",
      "Experienced in cross-cultural collaboration.\n",
      "Chinese (Simplified): Aspiring to learn in the future.LLM Engineering: Master AI, Large Language Models & Agents\n",
      "Platform: Udemy | Company: Ligacy Team | Status: In progress (50%)\n",
      "Professional Certificate - build and deploy LLM applications while mastering generative AI, RAG, QLoRA, AI agents, etc. Aug 2025 - Present \n",
      "IX. LANGUAGES\n",
      "VIII. CERTIFICATES\n",
      "Machine Learning A-Z: AI, Python & R + ChatGPT Prize [2025]\n",
      "Platform: Udemy | Company: SuperDataScienceTeam | Status: Completed\n",
      "Professional Certificate - Completed 100% of 47-hour Machine Learning fundamentals and Python implementation\n",
      "through hands-on projects.\n",
      "TensorFlow for Deep Learning Bootcamp\n",
      "Platform: Udemy | Company: ZTM | Status: Completed\n",
      "Professional Certificate - Completed 100% of 62.5-hour comprehensive training in neural networks implementation\n",
      "through hands-on projects.\n",
      "The Complete Python Bootcamp From Zero to Hero in Python\n",
      "Platform: Udemy | Status: Completed\n",
      "Professional Certificate - Advanced core Python programming concepts through coding exercises, projects Dec 2024 - Mar 2025 June 2024 - May 2025\n",
      "Dec 2024 - June 2025\n"
     ]
    }
   ],
   "source": [
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc09439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../resume/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07736204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Khang Bui Tran Duy, a highly motivated third-year Computer Science student at Ho Chi Minh City University of Technology with a CPA of 3.6/4.0. My expertise lies in Machine Learning, Deep Learning, and Reinforcement Learning, evidenced by my ongoing research at the Optimization AI Lab on Continual Learning strategies.Unlike a typical developer, I possess a strong 'Research-to-Production' mindset. I have hands-on experience building end-to-end pipelines—from data preprocessing and algorithm design (using PyTorch/TensorFlow) to model deployment (using Docker/FastAPI). I am eager to collaborate with experts to tackle challenging problems in Computer Vision and NLP, aiming to build scalable, intelligent systems that drive real-world impact.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a45458",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Duy Khang\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd110b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{resume}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f2ace",
   "metadata": {},
   "source": [
    "### Build the chat function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ad76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\" : \"system\", \"content\" : system_prompt }] + history +[{\"role\" : \"user\", \"content\" : message}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model = model,\n",
    "        messages= messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c5c0dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e9070",
   "metadata": {},
   "source": [
    "## Try to evaluate the answer of the chatbot by another Ollama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e550491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n",
    "    score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a52a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{resume}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dba309",
   "metadata": {},
   "source": [
    "### Create a evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8aedb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75402000",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\" \n",
    ")\n",
    "\n",
    "deepseek_name = \"deepseek-r1:7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_deepseek(text: str):\n",
    "    if \"</think>\" in text:\n",
    "        text = text.split(\"</think>\")[-1]\n",
    "    match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07107e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    print(f\"Đang gửi yêu cầu tới Ollama ({deepseek_name})...\")\n",
    "    system_prompt = (\n",
    "        \"You are an AI Evaluator. \"\n",
    "        \"You must output ONLY a valid JSON object. \"\n",
    "        \"Do not include any text outside the JSON. \"\n",
    "        \"The JSON must strictly follow this schema:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"is_acceptable\": true/false,\\n'\n",
    "        '  \"feedback\": \"string evaluation\",\\n'\n",
    "        '  \"score\": integer_0_to_10\\n'\n",
    "        \"}\"\n",
    "    )\n",
    "\n",
    "    user_content = evaluator_user_prompt(reply, message, history)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deepseek_name,\n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"}, \n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        raw_content = response.choices[0].message.content\n",
    "        json_data = extract_json_from_deepseek(raw_content)\n",
    "\n",
    "        if json_data:\n",
    "            return Evaluation.model_validate(json_data)\n",
    "        else:\n",
    "            raise ValueError(\"Không tìm thấy JSON hợp lệ trong phản hồi.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi parse: {e}\")\n",
    "        return Evaluation(\n",
    "            is_acceptable=False,\n",
    "            feedback=f\"System Error: {str(e)}\", \n",
    "            score=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9cb3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=model, messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01ec79d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I currently do not hold a patent. My focus is on research and development in the fields of Machine Learning, Deep Learning, and Reinforcement Learning, particularly through my work in the Optimization AI Lab. While I strive to contribute to advancements in these areas and collaborate on innovative projects, I have not yet secured any patents. If you have further questions about my work or projects, feel free to ask!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83da9d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang gửi yêu cầu tới Ollama (deepseek-r1:7b)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The assistant provided a clear and honest answer regarding the lack of current patents, while also highlighting their focus areas and willingness to discuss further.', score=9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf2d0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bad30f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=model, messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f238edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang gửi yêu cầu tới Ollama (deepseek-r1:7b)...\n",
      "Passed evaluation - returning reply\n",
      "Đang gửi yêu cầu tới Ollama (deepseek-r1:7b)...\n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
